{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. Human readable title for snippet block:IFiles","title":"Home"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. Human readable title for snippet block:IFiles","title":"Project layout"},{"location":"api/","text":"files_file_create(context: 'Context', data_dict: 'dict[str, Any]') -> 'dict[str, Any]' Create a new file. This action passes uploaded file to the storage without strict validation. File is converted into standard upload object and everything else is controlled by storage. The same file may be uploaded to one storage and rejected by other, depending on configuration. This action is way too powerful to use it directly. The recommended approach is to register a different action for handling specific type of uploads and call current action internally. When uploading a real file(or using werkqeug.datastructures.FileStorage ), name parameter can be omited. In this case, the name of uploaded file is used. ckanapi action files_file_create upload@path/to/file.txt When uploading a raw content of the file using string or bytes object, name is mandatory. ckanapi action files_file_create upload@<(echo -n \"hello world\") name=file.txt Requires storage with CREATE capability. Params: name : human-readable name of the file. Default: guess using upload field storage : name of the storage that will handle the upload. Default: default upload : content of the file as string, bytes, file descriptor or uploaded file Returns: dictionary with file details. files_file_delete(context: 'Context', data_dict: 'dict[str, Any]') -> 'dict[str, Any]' Remove file from storage. Unlike packages, file has no state field. Removal usually means that file details removed from DB and file itself removed from the storage. Some storage can implement revisions of the file and keep archived versions or backups. Check storage documentation if you need to know whether there are chances that file is not completely removed with this operation. Requires storage with REMOVE capability. ckanapi action files_file_delete id=226056e2-6f83-47c5-8bd2-102e2b82ab9a Params: id : ID of the file completed : use False to remove incomplete uploads. Default: True Returns: dictionary with details of the removed file. files_file_pin(context: 'Context', data_dict: 'dict[str, Any]') -> 'dict[str, Any]' Pin file to the current owner. Pinned file cannot be transfered to a different owner. Use it to guarantee that file referred by entity is not accidentally transferred to a different owner. Params: id : ID of the file completed : use False to pin incomplete uploads. Default: True Returns: dictionary with details of updated file files_file_rename(context: 'Context', data_dict: 'dict[str, Any]') -> 'dict[str, Any]' Rename the file. This action changes human-readable name of the file, which is stored in DB. Real location of the file in the storage is not modified. ckanapi action files_file_show \\ id=226056e2-6f83-47c5-8bd2-102e2b82ab9a \\ name=new-name.txt Params: id : ID of the file name : new name of the file completed : use False to rename incomplete uploads. Default: True Returns: dictionary with file details files_file_scan(context: 'Context', data_dict: 'dict[str, Any]') -> 'dict[str, Any]' List files of the owner This action internally calls files_file_search, but with static values of owner filters. If owner is not specified, files filtered by current user. If owner is specified, user must pass authorization check to see files. Params: owner_id : ID of the owner owner_type : type of the owner The all other parameters are passed as-is to files_file_search . Returns: count : total number of files matching filters results : array of dictionaries with file details. files_file_search(context: 'Context', data_dict: 'dict[str, Any]') -> 'dict[str, Any]' Search files. This action is not stabilized yet and will change in future. Provides an ability to search files using exact filter by name, content_type, size, owner, etc. Results are paginated and returned in package_search manner, as dict with count and results items. All columns of File model can be used as filters. Before the search, type of column and type of filter value are compared. If they are the same, original values are used in search. If type different, column value and filter value are casted to string. This request produces size = 10 SQL expression: ckanapi action files_file_search size:10 This request produces size::text = '10' SQL expression: ckanapi action files_file_search size=10 Even though results are usually not changed, using correct types leads to more efficient search. Apart from File columns, the following Owner properties can be used for searching: owner_id , owner_type , pinned . storage_data and plugin_data are dictionaries. Filter's value for these fields used as a mask. For example, storage_data={\"a\": {\"b\": 1}} matches any File with storage_data containing item a with value that contains b=1 . This works only with data represented by nested dictionaries, without other structures, like list or sets. Experimental feature: File columns can be passed as a pair of operator and value. This feature will be replaced by strictly defined query language at some point: ckanapi action files_file_search size:'[\"<\", 100]' content_type:'[\"like\", \"text/%\"]' Fillowing operators are accepted: = , < , > , != , like Params: start : index of first row in result/number of rows to skip. Default: 0 rows : number of rows to return. Default: 10 sort : name of File column used for sorting. Default: name reverse : sort results in descending order. Default: False storage_data : mask for storage_data column. Default: {} plugin_data : mask for plugin_data column. Default: {} owner_type: str : show only specific owner id if present. Default: None owner_type : show only specific owner type if present. Default: None pinned : show only pinned/unpinned items if present. Default: None completed : use False to search incomplete uploads. Default: True Returns: count : total number of files matching filters results : array of dictionaries with file details. files_file_search_by_user(context: 'Context', data_dict: 'dict[str, Any]') -> 'dict[str, Any]' Internal action. Do not use it. files_file_show(context: 'Context', data_dict: 'dict[str, Any]') -> 'dict[str, Any]' Show file details. This action only displays information from DB record. There is no way to get the content of the file using this action(or any other API action). ckanapi action files_file_show id=226056e2-6f83-47c5-8bd2-102e2b82ab9a Params: id : ID of the file completed : use False to show incomplete uploads. Default: True Returns: dictionary with file details files_file_unpin(context: 'Context', data_dict: 'dict[str, Any]') -> 'dict[str, Any]' Pin file to the current owner. Pinned file cannot be transfered to a different owner. Use it to guarantee that file referred by entity is not accidentally transferred to a different owner. Params: id : ID of the file completed : use False to unpin incomplete uploads. Default: True Returns: dictionary with details of updated file files_multipart_complete(context: 'Context', data_dict: 'dict[str, Any]') -> 'dict[str, Any]' Finalize multipart upload and transform it into completed file. Depending on storage this action may require additional parameters. But usually it just takes ID and verify that content type, size and hash provided when upload was initialized, much the actual value. If data is valid and file is completed inside the storage, new File entry with file details created in DB and file can be used just as any normal file. Requires storage with MULTIPART capability. Params: id : ID of the incomplete upload Returns: dictionary with details of the created file files_multipart_refresh(context: 'Context', data_dict: 'dict[str, Any]') -> 'dict[str, Any]' Refresh details of incomplete upload. Can be used if upload process was interrupted and client does not how many bytes were already uploaded. Requires storage with MULTIPART capability. Params: id : ID of the incomplete upload Returns: dictionary with details of the updated upload files_multipart_start(context: 'Context', data_dict: 'dict[str, Any]') -> 'dict[str, Any]' Initialize multipart(resumable,continuous,signed,etc) upload. Apart from standard parameters, different storages can require additional data, so always check documentation of the storage before initiating multipart upload. When upload initialized, storage usually returns details required for further upload. It may be a presigned URL for direct upload, or just an ID of upload which must be used with files_multipart_update . Requires storage with MULTIPART capability. Params: storage : name of the storage that will handle the upload. Default: default name : name of the uploaded file. content_type : MIMEtype of the uploaded file. Used for validation size : Expected size of upload. Used for validation hash : Expected content hash. If present, used for validation. Returns: dictionary with details of initiated upload. Depends on used storage files_multipart_update(context: 'Context', data_dict: 'dict[str, Any]') -> 'dict[str, Any]' Update incomplete upload. Depending on storage this action may require additional parameters. Most likely, upload with the fragment of uploaded file. Requires storage with MULTIPART capability. Params: id : ID of the incomplete upload Returns: dictionary with details of the updated upload files_resource_upload(context: 'Context', data_dict: 'dict[str, Any]') Create a new file inside resource storage. This action internally calls files_file_create with ignore_auth=True and always uses resources storage. New file is not attached to resource. You need to call files_transfer_ownership manually, when resource created. Params: name : human-readable name of the file. Default: guess using upload field upload : content of the file as string, bytes, file descriptor or uploaded file Returns: dictionary with file details. files_transfer_ownership(context: 'Context', data_dict: 'dict[str, Any]') -> 'dict[str, Any]' Transfer file ownership. Depending on storage this action may require additional parameters. Most likely, upload with the fragment of uploaded file. Params: id : ID of the file upload completed : use False to transfer incomplete uploads. Default: True owner_id : ID of the new owner owner_type : type of the new owner force : move file even if it's pinned. Default: False pin : pin file after transfer to stop future transfers. Default: False Returns: dictionary with details of updated file","title":"API"},{"location":"api/#files_file_createcontext-context-data_dict-dictstr-any-dictstr-any","text":"Create a new file. This action passes uploaded file to the storage without strict validation. File is converted into standard upload object and everything else is controlled by storage. The same file may be uploaded to one storage and rejected by other, depending on configuration. This action is way too powerful to use it directly. The recommended approach is to register a different action for handling specific type of uploads and call current action internally. When uploading a real file(or using werkqeug.datastructures.FileStorage ), name parameter can be omited. In this case, the name of uploaded file is used. ckanapi action files_file_create upload@path/to/file.txt When uploading a raw content of the file using string or bytes object, name is mandatory. ckanapi action files_file_create upload@<(echo -n \"hello world\") name=file.txt Requires storage with CREATE capability. Params: name : human-readable name of the file. Default: guess using upload field storage : name of the storage that will handle the upload. Default: default upload : content of the file as string, bytes, file descriptor or uploaded file Returns: dictionary with file details.","title":"files_file_create(context: 'Context', data_dict: 'dict[str, Any]') -&gt; 'dict[str, Any]'"},{"location":"api/#files_file_deletecontext-context-data_dict-dictstr-any-dictstr-any","text":"Remove file from storage. Unlike packages, file has no state field. Removal usually means that file details removed from DB and file itself removed from the storage. Some storage can implement revisions of the file and keep archived versions or backups. Check storage documentation if you need to know whether there are chances that file is not completely removed with this operation. Requires storage with REMOVE capability. ckanapi action files_file_delete id=226056e2-6f83-47c5-8bd2-102e2b82ab9a Params: id : ID of the file completed : use False to remove incomplete uploads. Default: True Returns: dictionary with details of the removed file.","title":"files_file_delete(context: 'Context', data_dict: 'dict[str, Any]') -&gt; 'dict[str, Any]'"},{"location":"api/#files_file_pincontext-context-data_dict-dictstr-any-dictstr-any","text":"Pin file to the current owner. Pinned file cannot be transfered to a different owner. Use it to guarantee that file referred by entity is not accidentally transferred to a different owner. Params: id : ID of the file completed : use False to pin incomplete uploads. Default: True Returns: dictionary with details of updated file","title":"files_file_pin(context: 'Context', data_dict: 'dict[str, Any]') -&gt; 'dict[str, Any]'"},{"location":"api/#files_file_renamecontext-context-data_dict-dictstr-any-dictstr-any","text":"Rename the file. This action changes human-readable name of the file, which is stored in DB. Real location of the file in the storage is not modified. ckanapi action files_file_show \\ id=226056e2-6f83-47c5-8bd2-102e2b82ab9a \\ name=new-name.txt Params: id : ID of the file name : new name of the file completed : use False to rename incomplete uploads. Default: True Returns: dictionary with file details","title":"files_file_rename(context: 'Context', data_dict: 'dict[str, Any]') -&gt; 'dict[str, Any]'"},{"location":"api/#files_file_scancontext-context-data_dict-dictstr-any-dictstr-any","text":"List files of the owner This action internally calls files_file_search, but with static values of owner filters. If owner is not specified, files filtered by current user. If owner is specified, user must pass authorization check to see files. Params: owner_id : ID of the owner owner_type : type of the owner The all other parameters are passed as-is to files_file_search . Returns: count : total number of files matching filters results : array of dictionaries with file details.","title":"files_file_scan(context: 'Context', data_dict: 'dict[str, Any]') -&gt; 'dict[str, Any]'"},{"location":"api/#files_file_searchcontext-context-data_dict-dictstr-any-dictstr-any","text":"Search files. This action is not stabilized yet and will change in future. Provides an ability to search files using exact filter by name, content_type, size, owner, etc. Results are paginated and returned in package_search manner, as dict with count and results items. All columns of File model can be used as filters. Before the search, type of column and type of filter value are compared. If they are the same, original values are used in search. If type different, column value and filter value are casted to string. This request produces size = 10 SQL expression: ckanapi action files_file_search size:10 This request produces size::text = '10' SQL expression: ckanapi action files_file_search size=10 Even though results are usually not changed, using correct types leads to more efficient search. Apart from File columns, the following Owner properties can be used for searching: owner_id , owner_type , pinned . storage_data and plugin_data are dictionaries. Filter's value for these fields used as a mask. For example, storage_data={\"a\": {\"b\": 1}} matches any File with storage_data containing item a with value that contains b=1 . This works only with data represented by nested dictionaries, without other structures, like list or sets. Experimental feature: File columns can be passed as a pair of operator and value. This feature will be replaced by strictly defined query language at some point: ckanapi action files_file_search size:'[\"<\", 100]' content_type:'[\"like\", \"text/%\"]' Fillowing operators are accepted: = , < , > , != , like Params: start : index of first row in result/number of rows to skip. Default: 0 rows : number of rows to return. Default: 10 sort : name of File column used for sorting. Default: name reverse : sort results in descending order. Default: False storage_data : mask for storage_data column. Default: {} plugin_data : mask for plugin_data column. Default: {} owner_type: str : show only specific owner id if present. Default: None owner_type : show only specific owner type if present. Default: None pinned : show only pinned/unpinned items if present. Default: None completed : use False to search incomplete uploads. Default: True Returns: count : total number of files matching filters results : array of dictionaries with file details.","title":"files_file_search(context: 'Context', data_dict: 'dict[str, Any]') -&gt; 'dict[str, Any]'"},{"location":"api/#files_file_search_by_usercontext-context-data_dict-dictstr-any-dictstr-any","text":"Internal action. Do not use it.","title":"files_file_search_by_user(context: 'Context', data_dict: 'dict[str, Any]') -&gt; 'dict[str, Any]'"},{"location":"api/#files_file_showcontext-context-data_dict-dictstr-any-dictstr-any","text":"Show file details. This action only displays information from DB record. There is no way to get the content of the file using this action(or any other API action). ckanapi action files_file_show id=226056e2-6f83-47c5-8bd2-102e2b82ab9a Params: id : ID of the file completed : use False to show incomplete uploads. Default: True Returns: dictionary with file details","title":"files_file_show(context: 'Context', data_dict: 'dict[str, Any]') -&gt; 'dict[str, Any]'"},{"location":"api/#files_file_unpincontext-context-data_dict-dictstr-any-dictstr-any","text":"Pin file to the current owner. Pinned file cannot be transfered to a different owner. Use it to guarantee that file referred by entity is not accidentally transferred to a different owner. Params: id : ID of the file completed : use False to unpin incomplete uploads. Default: True Returns: dictionary with details of updated file","title":"files_file_unpin(context: 'Context', data_dict: 'dict[str, Any]') -&gt; 'dict[str, Any]'"},{"location":"api/#files_multipart_completecontext-context-data_dict-dictstr-any-dictstr-any","text":"Finalize multipart upload and transform it into completed file. Depending on storage this action may require additional parameters. But usually it just takes ID and verify that content type, size and hash provided when upload was initialized, much the actual value. If data is valid and file is completed inside the storage, new File entry with file details created in DB and file can be used just as any normal file. Requires storage with MULTIPART capability. Params: id : ID of the incomplete upload Returns: dictionary with details of the created file","title":"files_multipart_complete(context: 'Context', data_dict: 'dict[str, Any]') -&gt; 'dict[str, Any]'"},{"location":"api/#files_multipart_refreshcontext-context-data_dict-dictstr-any-dictstr-any","text":"Refresh details of incomplete upload. Can be used if upload process was interrupted and client does not how many bytes were already uploaded. Requires storage with MULTIPART capability. Params: id : ID of the incomplete upload Returns: dictionary with details of the updated upload","title":"files_multipart_refresh(context: 'Context', data_dict: 'dict[str, Any]') -&gt; 'dict[str, Any]'"},{"location":"api/#files_multipart_startcontext-context-data_dict-dictstr-any-dictstr-any","text":"Initialize multipart(resumable,continuous,signed,etc) upload. Apart from standard parameters, different storages can require additional data, so always check documentation of the storage before initiating multipart upload. When upload initialized, storage usually returns details required for further upload. It may be a presigned URL for direct upload, or just an ID of upload which must be used with files_multipart_update . Requires storage with MULTIPART capability. Params: storage : name of the storage that will handle the upload. Default: default name : name of the uploaded file. content_type : MIMEtype of the uploaded file. Used for validation size : Expected size of upload. Used for validation hash : Expected content hash. If present, used for validation. Returns: dictionary with details of initiated upload. Depends on used storage","title":"files_multipart_start(context: 'Context', data_dict: 'dict[str, Any]') -&gt; 'dict[str, Any]'"},{"location":"api/#files_multipart_updatecontext-context-data_dict-dictstr-any-dictstr-any","text":"Update incomplete upload. Depending on storage this action may require additional parameters. Most likely, upload with the fragment of uploaded file. Requires storage with MULTIPART capability. Params: id : ID of the incomplete upload Returns: dictionary with details of the updated upload","title":"files_multipart_update(context: 'Context', data_dict: 'dict[str, Any]') -&gt; 'dict[str, Any]'"},{"location":"api/#files_resource_uploadcontext-context-data_dict-dictstr-any","text":"Create a new file inside resource storage. This action internally calls files_file_create with ignore_auth=True and always uses resources storage. New file is not attached to resource. You need to call files_transfer_ownership manually, when resource created. Params: name : human-readable name of the file. Default: guess using upload field upload : content of the file as string, bytes, file descriptor or uploaded file Returns: dictionary with file details.","title":"files_resource_upload(context: 'Context', data_dict: 'dict[str, Any]')"},{"location":"api/#files_transfer_ownershipcontext-context-data_dict-dictstr-any-dictstr-any","text":"Transfer file ownership. Depending on storage this action may require additional parameters. Most likely, upload with the fragment of uploaded file. Params: id : ID of the file upload completed : use False to transfer incomplete uploads. Default: True owner_id : ID of the new owner owner_type : type of the new owner force : move file even if it's pinned. Default: False pin : pin file after transfer to stop future transfers. Default: False Returns: dictionary with details of updated file","title":"files_transfer_ownership(context: 'Context', data_dict: 'dict[str, Any]') -&gt; 'dict[str, Any]'"},{"location":"shared/","text":"get_storage(name: 'str | None' = None) -> 'Storage' Return existing storage instance. Storages are initialized when plugin is loaded. As result, this function always returns the same storage object for the given name. If no name specified, default storage is returned. Example: default_storage = get_storage() storage = get_storage(\"storage name\") make_storage(name: 'str', settings: 'dict[str, Any]') -> 'Storage' Initialize storage instance with specified settings. Storage adapter is defined by type key of the settings. All other settings depend on the specific adapter. Example: storage = make_storage(\"memo\", {\"type\": \"files:redis\"}) make_upload(value: 'FileStorage | Upload | tempfile.SpooledTemporaryFile[Any] | TextIOWrapper | bytes | bytearray | BinaryIO') -> 'Upload' Convert value into Upload object Use this function for simple and reliable initialization of Upload object. Avoid creating Upload manually, unless you are 100% sure you can provide correct MIMEtype, size and stream. Example: storage.upload(\"file.txt\", make_upload(b\"hello world\")) with_task_queue(func: 'Any', name: 'str | None' = None) Decorator for functions that schedule tasks. Decorated function automatically initializes separate task queue that is processed when function is finished. All tasks receive function's result as execution data(first argument to Task.run). Without this decorator, you have to manually create task queue context before queuing tasks. Example: @with_task_queue def my_action(context, data_dict): ... add_task(task: 'Task') Add task to the current task queue. This function can be called only inside task queue context. Such context initialized automatically inside functions decorated with with_task_queue : @with_task_queue def taks_producer(): add_task(...) task_producer() If task queue context can be initialized manually using TaskQueue and with statement: queue = TaskQueue() with queue: add_task(...) queue.process(execution_data)","title":"Shared"},{"location":"shared/#get_storagename-str-none-none-storage","text":"Return existing storage instance. Storages are initialized when plugin is loaded. As result, this function always returns the same storage object for the given name. If no name specified, default storage is returned. Example: default_storage = get_storage() storage = get_storage(\"storage name\")","title":"get_storage(name: 'str | None' = None) -&gt; 'Storage'"},{"location":"shared/#make_storagename-str-settings-dictstr-any-storage","text":"Initialize storage instance with specified settings. Storage adapter is defined by type key of the settings. All other settings depend on the specific adapter. Example: storage = make_storage(\"memo\", {\"type\": \"files:redis\"})","title":"make_storage(name: 'str', settings: 'dict[str, Any]') -&gt; 'Storage'"},{"location":"shared/#make_uploadvalue-filestorage-upload-tempfilespooledtemporaryfileany-textiowrapper-bytes-bytearray-binaryio-upload","text":"Convert value into Upload object Use this function for simple and reliable initialization of Upload object. Avoid creating Upload manually, unless you are 100% sure you can provide correct MIMEtype, size and stream. Example: storage.upload(\"file.txt\", make_upload(b\"hello world\"))","title":"make_upload(value: 'FileStorage | Upload | tempfile.SpooledTemporaryFile[Any] | TextIOWrapper | bytes | bytearray | BinaryIO') -&gt; 'Upload'"},{"location":"shared/#with_task_queuefunc-any-name-str-none-none","text":"Decorator for functions that schedule tasks. Decorated function automatically initializes separate task queue that is processed when function is finished. All tasks receive function's result as execution data(first argument to Task.run). Without this decorator, you have to manually create task queue context before queuing tasks. Example: @with_task_queue def my_action(context, data_dict): ...","title":"with_task_queue(func: 'Any', name: 'str | None' = None)"},{"location":"shared/#add_tasktask-task","text":"Add task to the current task queue. This function can be called only inside task queue context. Such context initialized automatically inside functions decorated with with_task_queue : @with_task_queue def taks_producer(): add_task(...) task_producer() If task queue context can be initialized manually using TaskQueue and with statement: queue = TaskQueue() with queue: add_task(...) queue.process(execution_data)","title":"add_task(task: 'Task')"}]}